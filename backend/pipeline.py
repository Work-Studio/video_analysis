"""åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®èª¿åœãƒ­ã‚¸ãƒƒã‚¯."""

import json
from pathlib import Path
from typing import Optional

import aiofiles

from backend.models.gemini_client import GeminiClient
from backend.models.risk_assessor import RiskAssessor
from backend.store import (
    PROJECT_STEPS,
    PipelineAlreadyRunningError,
    ProjectNotFoundError,
    ProjectStore,
)
from backend.utils.logging_utils import setup_logger


class AnalysisPipeline:
    """å‹•ç”»åˆ†æã®å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †æ¬¡å®Ÿè¡Œã™ã‚‹."""

    def __init__(
        self,
        *,
        store: ProjectStore,
        gemini_client: GeminiClient,
        risk_assessor: RiskAssessor,
        logger_name: str = "analysis_pipeline",
    ) -> None:
        self.store = store
        self.gemini_client = gemini_client
        self.risk_assessor = risk_assessor
        self.logger = setup_logger(logger_name)

    async def run(self, project_id: str) -> None:
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ."""

        try:
            await self.store.mark_pipeline_started(project_id)
        except PipelineAlreadyRunningError:
            # æ—¢ã«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°æ¸ˆã¿ã§ã‚ã‚Œã°ãã®ã¾ã¾ç¶™ç¶š
            self.logger.info("Pipeline already running for project %s", project_id)
        except ProjectNotFoundError:
            self.logger.warning("Project %s not found. Abort pipeline.", project_id)
            return

        try:
            project = await self.store.get_project(project_id)
            video_path = Path(project.video_path)

            workspace_dir = Path(project.workspace_dir)

            media_type = project.media_type

            (
                transcript,
                transcript_path,
                transcript_source,
                transcript_note,
            ) = await self._run_transcription(
                project_id, video_path, workspace_dir, media_type
            )
            ocr_text, ocr_path, ocr_note = await self._run_ocr(project_id, video_path, workspace_dir)
            video_result, video_path_json, video_note = await self._run_visual_analysis(
                project_id, video_path, workspace_dir, media_type
            )
            risk_result, risk_path = await self._run_risk(
                project_id,
                transcript,
                ocr_text,
                video_result,
                workspace_dir,
            )
            final_report = self._build_final_report(
                transcript,
                ocr_text,
                video_result,
                transcript_path,
                ocr_path,
                video_path_json,
                risk_path,
                risk_result,
                transcript_source,
                transcript_note,
                ocr_note,
                video_note,
            )

            await self.store.mark_pipeline_completed(project_id, final_report)
            self.logger.info("Pipeline completed for project %s", project_id)
        except Exception as exc:  # pylint: disable=broad-except
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ failed ã«ã—ã¦ãƒ­ã‚°ã‚’æ®‹ã™
            self.logger.exception("Pipeline execution failed for %s", project_id)
            await self.store.mark_pipeline_failed(project_id, str(exc))
            raise

    async def _run_transcription(
        self, project_id: str, media_path: Path, workspace_dir: Path, media_type: str
    ) -> tuple[str, Path, str, Optional[str]]:
        """éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚¹ãƒ†ãƒƒãƒ—."""

        step = PROJECT_STEPS[0]
        await self.store.mark_step_running(project_id, step)
        transcript_source = "gemini"
        transcript_note: Optional[str] = None
        if media_type == "image":
            self.logger.info("Skipping transcription for %s (image asset).", project_id)
            transcript = ""
            transcript_source = "skipped"
            transcript_note = "é™æ­¢ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãŸã‚éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚"
            formatted = "ğŸ—£ï¸ éŸ³å£°æ–‡å­—èµ·ã“ã—\né™æ­¢ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãŸã‚éŸ³å£°æ–‡å­—èµ·ã“ã—ã¯å®Ÿæ–½ã—ã¾ã›ã‚“ã€‚"
            transcript_path = await self._save_text_file(
                workspace_dir,
                "transcription.txt",
                "é™æ­¢ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãŸã‚éŸ³å£°æ–‡å­—èµ·ã“ã—ã¯å®Ÿæ–½ã—ã¾ã›ã‚“ã€‚",
            )
        else:
            try:
                transcript = await self.gemini_client.transcribe_audio(media_path)
            except Exception as gemini_error:
                self.logger.warning(
                    "Gemini transcription failed for %s: %s",
                    project_id,
                    gemini_error,
                )
                transcript = (
                    "æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸã€‚éŸ³å£°ãŒç¢ºèªã§ããªã„ãŸã‚ã€"
                    "å†åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚„åˆ¥ãƒ¢ãƒ‡ãƒ«ã§ã®è§£æã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
                )
                transcript_source = "fallback"
                transcript_note = (
                    "Gemini ã§ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼æ–‡ç« ã‚’è¿”å´ã—ã¾ã—ãŸã€‚"
                )
            formatted = self._format_transcript(transcript)
            transcript_path = await self._save_text_file(
                workspace_dir, "transcription.txt", transcript or formatted
            )
        await self.store.update_status(
            project_id,
            step,
            formatted,
            data={
                "transcript": transcript,
                "formatted": formatted,
                "file_path": str(transcript_path),
                "source": transcript_source,
                "note": transcript_note,
            },
        )
        return transcript, transcript_path, transcript_source, transcript_note

    async def _run_ocr(
        self, project_id: str, video_path: Path, workspace_dir: Path
    ) -> tuple[str, Path, Optional[str]]:
        """OCR ã‚¹ãƒ†ãƒƒãƒ—."""

        step = PROJECT_STEPS[1]
        await self.store.mark_step_running(project_id, step)
        ocr_note: Optional[str] = None
        try:
            ocr_text = await self.gemini_client.extract_ocr(video_path)
        except Exception as exc:
            self.logger.warning(
                "Gemini OCR failed for %s: %s", project_id, exc
            )
            ocr_text = (
                "OCR æŠ½å‡ºã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è©²å½“ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ–‡å­—ãŒå–å¾—ã§ããªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            )
            ocr_note = "Gemini OCR ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼æ–‡ç« ã‚’è¿”å´ã—ã¾ã—ãŸã€‚"
        annotations = [
            line.strip()
            for line in ocr_text.splitlines()
            if "â€»" in line
        ]
        formatted = self._format_ocr_text(ocr_text)
        ocr_path = await self._save_text_file(workspace_dir, "ocr.txt", ocr_text)
        await self.store.update_status(
            project_id,
            step,
            formatted,
            data={
                "ocr_text": ocr_text,
                "formatted": formatted,
                "file_path": str(ocr_path),
                "note": ocr_note,
                "annotations": annotations,
            },
        )
        return ocr_text, ocr_path, ocr_note

    async def _run_visual_analysis(
        self, project_id: str, media_path: Path, workspace_dir: Path, media_type: str
    ) -> tuple[dict, Path, Optional[str]]:
        """æ˜ åƒè§£æã‚¹ãƒ†ãƒƒãƒ—."""

        step = PROJECT_STEPS[2]
        await self.store.mark_step_running(project_id, step)
        video_note: Optional[str] = None
        try:
            if media_type == "image":
                video_result = await self.gemini_client.analyze_image(media_path)
                video_note = "Gemini ã«ã‚ˆã‚‹é™æ­¢ç”»è§£æã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚"
            else:
                video_result = await self.gemini_client.analyze_video_segments(media_path)
        except Exception as visual_error:
            self.logger.warning(
                "Gemini visual analysis failed for %s: %s",
                project_id,
                visual_error,
            )
            video_result = {
                "summary": (
                    "æ˜ åƒè§£æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸã€‚Gemini API ã‚­ãƒ¼ã®è¨­å®šã‚’ç¢ºèªã—å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
                ),
                "segments": [],
                "risk_flags": ["analysis-unavailable"],
            }
            video_note = (
                "Gemini ã®æ˜ åƒè§£æã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼çµæœã‚’è¿”å´ã—ã¾ã—ãŸã€‚"
            )
        formatted = self._format_video_analysis(video_result)
        if self._is_stub_video_result(video_result):
            if video_note is None:
                video_note = "Gemini API ã‚­ãƒ¼æœªè¨­å®šã®ãŸã‚ã‚¹ã‚¿ãƒ–è§£æçµæœã‚’è¿”å´ã—ã¾ã—ãŸã€‚"
            self.logger.info("Visual analysis returned stub result for %s.", project_id)
        video_path = await self._save_json_file(workspace_dir, "video_analysis.json", video_result)
        await self.store.update_status(
            project_id,
            step,
            formatted,
            data={
                "raw": video_result,
                "formatted": formatted,
                "file_path": str(video_path),
                "note": video_note,
            },
        )
        return video_result, video_path, video_note

    async def _run_risk(
        self,
        project_id: str,
        transcript: str,
        ocr_text: str,
        video_result: dict,
        workspace_dir: Path,
    ) -> tuple[dict, Path]:
        """Gemini ã‚’ç”¨ã„ãŸçµ±åˆãƒªã‚¹ã‚¯è©•ä¾¡."""

        step = PROJECT_STEPS[3]
        await self.store.mark_step_running(project_id, step)
        try:
            risk_result = await self.risk_assessor.assess(
                transcript=transcript,
                ocr_text=ocr_text,
                video_summary=video_result,
            )
            risk_result.setdefault("tags", [])
            burn_risk = self.risk_assessor.calculate_burn_risk(risk_result.get("tags") or [])
            risk_result["burn_risk"] = burn_risk
        except Exception as exc:  # pragma: no cover
            self.logger.exception("Risk assessment failed for %s", project_id)
            risk_result = {
                "social": {
                    "grade": "C",
                    "reason": "ãƒªã‚¹ã‚¯è©•ä¾¡ã«å¤±æ•—ã—ãŸãŸã‚æš«å®šè©•ä¾¡ã‚’è¿”å´ã—ã¦ã„ã¾ã™ã€‚",
                    "findings": [],
                },
                "legal": {
                    "grade": "æŠµè§¦ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹",
                    "reason": "ãƒªã‚¹ã‚¯è©•ä¾¡ã«å¤±æ•—ã—ãŸãŸã‚æš«å®šè©•ä¾¡ã‚’è¿”å´ã—ã¦ã„ã¾ã™ã€‚",
                    "recommendations": "Gemini ã®è¨­å®šã‚’ç¢ºèªã—ã€å†åº¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚",
                    "violations": [],
                    "findings": [],
                },
                "matrix": {"x_axis": "æ³•å‹™è©•ä¾¡", "y_axis": "ç¤¾ä¼šçš„æ„Ÿåº¦", "position": [1, 2]},
                "note": str(exc),
                "tags": [],
                "burn_risk": {"count": 0, "details": []},
            }
        formatted = self._format_risk(risk_result)
        risk_path = await self._save_json_file(workspace_dir, "risk_assessment.json", risk_result)
        await self.store.update_status(
            project_id,
            step,
            formatted,
            data={
                "risk": risk_result,
                "formatted": formatted,
                "file_path": str(risk_path),
            },
        )
        return risk_result, risk_path

    def _build_final_report(
        self,
        transcript: str,
        ocr_text: str,
        video_result: dict,
        transcript_path: Path,
        ocr_path: Path,
        video_path: Path,
        risk_path: Path,
        risk_result: dict,
        transcription_source: str,
        transcription_note: Optional[str],
        ocr_note: Optional[str],
        video_note: Optional[str],
    ) -> dict:
        """å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®çµæœã‚’äººãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã§ã¾ã¨ã‚ã‚‹."""

        transcript_section = self._format_transcript(transcript)
        ocr_section = self._format_ocr_text(ocr_text)
        video_section = self._format_video_analysis(video_result)

        ocr_annotations = [
            line.strip()
            for line in ocr_text.splitlines()
            if "â€»" in line
        ]

        burn_risk = risk_result.get("burn_risk") if isinstance(risk_result, dict) else None

        social_grade = risk_result.get("social", {}).get("grade", "N/A")
        legal_grade = risk_result.get("legal", {}).get("grade", "N/A")

        disclaimer = (
            "*æœ¬åˆ†æçµæœã¯å‚è€ƒç”¨é€”ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€ç¤¾ä¼šçš„ãƒ»æ³•çš„ãƒªã‚¹ã‚¯ã®ä¸å­˜åœ¨ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
        )

        metadata: dict[str, object] = {
            "transcription_source": transcription_source,
        }
        if transcription_note:
            metadata["transcription_note"] = transcription_note
        if ocr_note:
            metadata["ocr_note"] = ocr_note
        if video_note:
            metadata["video_note"] = video_note
        if ocr_annotations:
            metadata["ocr_annotations"] = ocr_annotations
        if burn_risk:
            metadata["burn_risk"] = burn_risk

        return {
            "summary": disclaimer,
            "sections": {
                "transcription": transcript_section,
                "ocr": ocr_section,
                "video_analysis": video_section,
            },
            "files": {
                "transcription": str(transcript_path),
                "ocr": str(ocr_path),
                "video_analysis": str(video_path),
                "risk_assessment": str(risk_path),
            },
            "metadata": metadata,
            "risk": risk_result,
        }

    def _format_transcript(self, transcript: str) -> str:
        excerpt = transcript.strip() or "éŸ³å£°ã‹ã‚‰æœ‰åŠ¹ãªãƒ†ã‚­ã‚¹ãƒˆã¯å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        return f"ğŸ—£ï¸ éŸ³å£°æ–‡å­—èµ·ã“ã—\n{excerpt}"

    def _format_ocr_text(self, ocr_text: str) -> str:
        excerpt = ocr_text.strip() or "å­—å¹•æƒ…å ±ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
        return f"ğŸ“ OCRå­—å¹•æŠœç²‹\n{excerpt}"

    def _format_video_analysis(self, video_result: dict) -> str:
        summary = video_result.get("summary") or "æ˜ åƒã«é–¢ã™ã‚‹ç‰¹è¨˜äº‹é …ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
        segments = video_result.get("segments") or []
        lines = [f"ğŸ¬ æ˜ åƒè§£æãƒ¬ãƒãƒ¼ãƒˆ\n{summary}"]
        if segments:
            lines.append("\nğŸ“‹ è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—")
            for segment in segments:
                label = segment.get("label", "æœªåˆ†é¡ã®è¡¨ç¾")
                description = segment.get("description", "")
                lines.append(f"- {label}")
                if description:
                    lines.append(f"  ãƒ»{description}")
                shots = segment.get("shots") or []
                for shot in shots:
                    timecode = shot.get("timecode", "timecodeä¸æ˜")
                    detail = shot.get("description", "")
                    lines.append(f"    - {timecode}: {detail}")
        risk_flags = video_result.get("risk_flags") or []
        if risk_flags:
            lines.append("\nâš ï¸ æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ")
            for flag in risk_flags:
                lines.append(f"- {flag}")
        return "\n".join(lines)

    def _format_risk(self, risk_result: dict) -> str:
        social = risk_result.get("social", {})
        legal = risk_result.get("legal", {})
        matrix = risk_result.get("matrix", {})
        lines = [
            "âš–ï¸ çµ±åˆãƒªã‚¹ã‚¯è©•ä¾¡",
            f"ç¤¾ä¼šçš„æ„Ÿåº¦: {social.get('grade', 'N/A')} - {social.get('reason', '')}",
            f"æ³•å‹™è©•ä¾¡: {legal.get('grade', 'N/A')} - {legal.get('reason', '')}",
        ]
        social_findings = social.get("findings") or []
        if social_findings:
            lines.append("  ãƒ»ç¤¾ä¼šçš„æ„Ÿåº¦æŒ‡æ‘˜:")
            for finding in social_findings[:5]:
                lines.append(
                    f"    - {finding.get('timecode', 'N/A')}: {finding.get('detail', '')}"
                )
        recommendations = legal.get("recommendations")
        if recommendations:
            lines.append(f"æ”¹å–„ææ¡ˆ: {recommendations}")
        legal_findings = legal.get("findings") or []
        if legal_findings:
            lines.append("  ãƒ»æ³•å‹™æŒ‡æ‘˜:")
            for finding in legal_findings[:5]:
                lines.append(
                    f"    - {finding.get('timecode', 'N/A')}: {finding.get('detail', '')}"
                )
        violations = legal.get("violations") or []
        if violations:
            lines.append("  ãƒ»æƒ³å®šã•ã‚Œã‚‹æŠµè§¦è¡¨ç¾:")
            for violation in violations[:5]:
                reference = violation.get("reference")
                expression = violation.get("expression", "")
                severity = violation.get("severity")
                detail = expression
                if severity:
                    detail = f"[{severity}] {detail}"
                if reference:
                    detail = f"{reference}: {detail}"
                lines.append(f"    - {detail}")
        burn_risk = risk_result.get("burn_risk") or {}
        if burn_risk.get("count"):
            lines.append(
                f"ç‚ä¸Šè£œæ­£: {burn_risk.get('grade', 'N/A')} ({burn_risk.get('label', '')}) å¹³å‡ãƒªã‚¹ã‚¯ {burn_risk.get('average', 'N/A')}"
            )
        position = matrix.get("position")
        if position:
            lines.append(f"ãƒã‚¸ã‚·ãƒ§ãƒ³: X={position[0]} / Y={position[1]}")
        tags = risk_result.get("tags") or []
        if tags:
            lines.append("\nğŸ§© ã‚¿ã‚°åˆ¥è©•ä¾¡")
            for tag in tags[:5]:
                lines.append(
                    f"- {tag.get('name', 'ä¸æ˜')}: {tag.get('grade', 'N/A')} / {tag.get('reason', '')}"
                )
        return "\n".join(lines)

    @staticmethod
    def _is_stub_video_result(result: dict) -> bool:
        summary = result.get("summary", "")
        risk_flags = result.get("risk_flags") or []
        if isinstance(summary, str) and summary.startswith("[stub]"):
            return True
        return any(
            flag in {"insight-unavailable", "analysis-unavailable"} for flag in risk_flags
        )

    async def _save_text_file(self, workspace_dir: Path, filename: str, content: str) -> Path:
        """ãƒ†ã‚­ã‚¹ãƒˆçµæœã‚’ uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜."""

        output_path = workspace_dir / filename
        async with aiofiles.open(output_path, "w", encoding="utf-8") as file_obj:
            await file_obj.write(content)
        return output_path

    async def _save_json_file(self, workspace_dir: Path, filename: str, payload: dict) -> Path:
        """JSON çµæœã‚’ uploads ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜."""

        output_path = workspace_dir / filename
        async with aiofiles.open(output_path, "w", encoding="utf-8") as file_obj:
            json_payload = json.dumps(payload, ensure_ascii=False, indent=2)
            await file_obj.write(json_payload)
        return output_path
